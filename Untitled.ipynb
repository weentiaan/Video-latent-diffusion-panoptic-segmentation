{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9384cb-9dee-4513-a3ce-2efad8bb13ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "class SemKITTI_DVPS_Dataset(Dataset):\n",
    "    def __init__(self, root, split='val',\n",
    "                 image_transform=None,\n",
    "                 GT_transform=None,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): 数据集根目录，例如 '/path/to/dataset'\n",
    "            split (str): 数据集的划分，'train' 或 'val'\n",
    "            image_transform: 对 RGB 图像进行预处理的 transform\n",
    "            depth_transform: 对深度图进行预处理的 transform\n",
    "            seg_transform: 对语义分割标签进行预处理的 transform\n",
    "            inst_transform: 对实例分割标签进行预处理的 transform\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.image_transform = image_transform\n",
    "        self.GT_transform = GT_transform\n",
    "        \n",
    "        self.samples = []  # 每个元素为一个字典，包含该样本的各个图片路径\n",
    "        split_dir = os.path.join(root, split)\n",
    "        all_files = sorted(os.listdir(split_dir))\n",
    "        \n",
    "        # 按照样本前缀分组，假设前缀为前4个字符（例如 \"0001\"）\n",
    "        sample_dict = {}\n",
    "        for file in all_files:\n",
    "            # 去除空格、统一小写\n",
    "            file_name_element = file.split(\"_\")#[00000_00000_depth_718]\n",
    "            scene=file_name_element[0]#标记场景\n",
    "            frame=file_name_element[1]#标记帧\n",
    "            \n",
    "            # if scene != \"000000\":#只加载第一组\n",
    "            #     continue\n",
    "                \n",
    "            if scene not in sample_dict:\n",
    "                sample_dict[scene] = {}\n",
    "                if frame not in sample_dict[scene]:\n",
    "                    sample_dict[scene][frame]={}\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if frame not in sample_dict[scene]:\n",
    "                    sample_dict[scene][frame]={}\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            # 根据文件名中包含的关键字确定图片类型\n",
    "            if 'depth' in file_name_element:\n",
    "                sample_dict[scene][frame]['depth'] = os.path.join(split_dir, file)\n",
    "                sample_dict[scene][frame]['focal'] = file_name_element[3].split(\".\")[0]\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if 'class.png' in file_name_element:\n",
    "                sample_dict[scene][frame]['class'] = os.path.join(split_dir, file)\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if 'instance.png' in file_name_element:\n",
    "                sample_dict[scene][frame]['instance'] = os.path.join(split_dir, file)\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if 'leftImg8bit.png' in file_name_element:\n",
    "                sample_dict[scene][frame]['Img'] = os.path.join(split_dir, file)\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        # 过滤出包含所有四种图片的样本frame\n",
    "        for scene, frames in sample_dict.items():\n",
    "            for frame, files in frames.items():\n",
    "                if all(key in files for key in ['depth', 'Img', 'class', 'instance']):\n",
    "                    self.samples.append(files)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        # 加载 RGB 图像，并转换为 RGB 格式\n",
    "        image = Image.open(sample['Img']).convert('RGB')\n",
    "        # 加载深度图（深度图可能为单通道图像）\n",
    "        depth = Image.open(sample['depth'])\n",
    "        # 加载语义分割标签，通常为单通道标签图\n",
    "        seg = Image.open(sample['class'])\n",
    "        # 加载实例分割标签\n",
    "        inst = Image.open(sample['instance'])\n",
    "        \n",
    "        # 对图像应用预处理 transform\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "        \n",
    "        \n",
    "        depth = GT_transforms(depth)\n",
    "        \n",
    "        seg = GT_transforms(seg)\n",
    "            \n",
    "        inst = GT_transforms(inst)\n",
    "        \n",
    "        return image, depth, seg, inst\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d532c17-7c45-4fc9-896a-4c99b0507b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_color_map(num_colors):\n",
    "    \"\"\"\n",
    "    生成一个包含 num_colors 个随机颜色的映射表。\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # 固定种子，保证每次生成相同的颜色\n",
    "    return np.random.randint(0, 256, (num_colors, 3), dtype=np.uint8)\n",
    "\n",
    "def colorize_panoptic(panoptic_map, colormap):\n",
    "    \"\"\"\n",
    "    根据 panoptic_map 中每个像素的 panoptic_id，从 colormap 中取对应颜色，\n",
    "    生成彩色图像。\n",
    "    \"\"\"\n",
    "    b,c,h, w = panoptic_map.shape\n",
    "    color_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    unique_ids = np.unique(panoptic_map[0,0,:,:])\n",
    "    for uid in unique_ids:\n",
    "        # 如果 uid 为 0 或 2550000，设定为黑色\n",
    "        if uid == 2550000:\n",
    "            color = np.array([0, 0, 0], dtype=np.uint8)\n",
    "        else:\n",
    "            # 使用 modulo 确保 uid 超过颜色数量时仍然可以映射\n",
    "            color = colormap[uid % len(colormap)]\n",
    "        color_image[panoptic_map[0,0,:,:] == uid] = color\n",
    "    return color_image\n",
    "# 定义颜色映射表，假设最多256种不同颜色\n",
    "num_colors = 256\n",
    "colormap = get_color_map(num_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346c1d3d-3f7f-48e9-b746-faf0ce222c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "1\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "2\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "3\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "4\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "5\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "6\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "7\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "8\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "9\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "10\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "11\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "12\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "13\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "14\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "15\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "16\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "17\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "18\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "19\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "20\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "21\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "22\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "23\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "24\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "25\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "26\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "27\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "28\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "29\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "30\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "31\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "32\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "33\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "34\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "35\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "36\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "37\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "38\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "39\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "40\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "41\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "42\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "43\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "44\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "45\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "46\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "47\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "48\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "49\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "50\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "51\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "52\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "53\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "54\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "55\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "56\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "57\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "58\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "59\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "60\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "61\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "62\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "63\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "64\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "65\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "66\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "67\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "68\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "69\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "70\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "71\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "72\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "73\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "74\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "75\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "76\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "77\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "78\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "79\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "80\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "81\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "82\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "83\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "84\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "85\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "86\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "87\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "88\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "89\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "90\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n",
      "91\n",
      "torch.Size([1, 1, 192, 640])\n",
      "(192, 640, 3)\n",
      "torch.Size([1, 3, 192, 640])\n",
      "torch.Size([1, 3, 195, 643])\n",
      "(195, 643, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m pooled_image \u001b[38;5;241m=\u001b[39m pooled_tensor\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(pooled_image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 49\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(pooled_image)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 保存图片为 \"output.png\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m img\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/autodl-tmp/test/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_output.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/LDMSeg/lib/python3.11/site-packages/PIL/Image.py:3108\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtobytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3108\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m   3109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3110\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset_root = '/root/autodl-tmp/video_sequence'  # 修改为你的数据集根目录\n",
    "\n",
    "    # 定义图像预处理\n",
    "    image_transforms = transforms.Compose([\n",
    "        transforms.Resize((192, 640)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    GT_transforms = transforms.Compose([\n",
    "        transforms.Resize((192, 640),interpolation=transforms.InterpolationMode.NEAREST),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    # 可根据需要为深度图单独定义 transform，例如仅做 resize 和 ToTensor\n",
    "    # 对于 segment 和 instance，由于它们是标签，通常不希望有归一化操作，可以直接转换为 Tensor\n",
    "    # 这里我们在 __getitem__ 中已处理\n",
    "\n",
    "    # 构造训练集\n",
    "    train_dataset = SemKITTI_DVPS_Dataset(root=dataset_root,\n",
    "                                          split='val',\n",
    "                                          image_transform=image_transforms,\n",
    "                                             GT_transform=GT_transforms)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    # 测试加载数据\n",
    "    i=0\n",
    "    max_pool = nn.MaxPool2d(kernel_size=2, stride=1,padding=1)\n",
    "    for images, depths, segments, instances in train_loader:\n",
    "        # print(\"RGB 图像 batch 尺寸:\", images.shape)       # 例如 [4, 3, 256, 512]\n",
    "        # print(\"深度图 batch 尺寸:\", depths.shape)          # 例如 [4, 1, 256, 512]\n",
    "        # print(\"语义标签 batch 尺寸:\", segments)       # 例如 [4, 256, 512]\n",
    "        # print(\"实例标签 batch 尺寸:\", instances.shape)      # 例如 [4, 256, 512]\n",
    "        # 生成彩色图像\n",
    "        pop=segments*10000+instances\n",
    "        print(pop.shape)\n",
    "        color_image = colorize_panoptic(pop, colormap)\n",
    "        print(color_image.shape)\n",
    "        img_tensor = torch.tensor(color_image, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "        print(img_tensor.shape)\n",
    "        # 3. 定义最大池化层，kernel_size=2, stride=2（对每个通道独立操作）\n",
    "        \n",
    "\n",
    "        pooled_tensor = max_pool(max_pool(max_pool(img_tensor)))\n",
    "        print(pooled_tensor.shape)\n",
    "        # 4. 转换回 NumPy 数组，并将通道维度移到最后，得到形状 (88, 620, 3)\n",
    "        pooled_image = pooled_tensor.squeeze(0).permute(1, 2, 0).numpy().astype(np.uint8)\n",
    "        print(pooled_image.shape)\n",
    "        img = Image.fromarray(pooled_image)\n",
    "\n",
    "        # 保存图片为 \"output.png\"\n",
    "        img.save(\"/root/autodl-tmp/test/\"+str(i)+\"_output.png\")\n",
    "        #flag=i%10\n",
    "        i=i+1\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6906a79-e3a0-40ec-8f0b-2b3461d516f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDMSeg",
   "language": "python",
   "name": "ldmseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9384cb-9dee-4513-a3ce-2efad8bb13ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "class SemKITTI_DVPS_Dataset(Dataset):\n",
    "    def __init__(self, root, split='train',\n",
    "                 image_transform=None,\n",
    "                 GT_transform=None,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): 数据集根目录，例如 '/path/to/dataset'\n",
    "            split (str): 数据集的划分，'train' 或 'val'\n",
    "            image_transform: 对 RGB 图像进行预处理的 transform\n",
    "            depth_transform: 对深度图进行预处理的 transform\n",
    "            seg_transform: 对语义分割标签进行预处理的 transform\n",
    "            inst_transform: 对实例分割标签进行预处理的 transform\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.image_transform = image_transform\n",
    "        self.GT_transform = GT_transform\n",
    "        \n",
    "        self.samples = []  # 每个元素为一个字典，包含该样本的各个图片路径\n",
    "        split_dir = os.path.join(root, split)\n",
    "        all_files = sorted(os.listdir(split_dir))\n",
    "        \n",
    "        # 按照样本前缀分组，假设前缀为前4个字符（例如 \"0001\"）\n",
    "        sample_dict = {}\n",
    "        for file in all_files:\n",
    "            # 去除空格、统一小写\n",
    "            file_name_element = file.split(\"_\")#[00000_00000_depth_718]\n",
    "            scene=file_name_element[0]#标记场景\n",
    "            frame=file_name_element[1]#标记帧\n",
    "            \n",
    "            # if scene != \"000000\":#只加载第一组\n",
    "            #     continue\n",
    "                \n",
    "            if scene not in sample_dict:\n",
    "                sample_dict[scene] = {}\n",
    "                if frame not in sample_dict[scene]:\n",
    "                    sample_dict[scene][frame]={}\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if frame not in sample_dict[scene]:\n",
    "                    sample_dict[scene][frame]={}\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            # 根据文件名中包含的关键字确定图片类型\n",
    "            if 'depth' in file_name_element:\n",
    "                sample_dict[scene][frame]['depth'] = os.path.join(split_dir, file)\n",
    "                sample_dict[scene][frame]['focal'] = file_name_element[3].split(\".\")[0]\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if 'class.png' in file_name_element:\n",
    "                sample_dict[scene][frame]['class'] = os.path.join(split_dir, file)\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if 'instance.png' in file_name_element:\n",
    "                sample_dict[scene][frame]['instance'] = os.path.join(split_dir, file)\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if 'leftImg8bit.png' in file_name_element:\n",
    "                sample_dict[scene][frame]['Img'] = os.path.join(split_dir, file)\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        # 过滤出包含所有四种图片的样本frame\n",
    "        for scene, frames in sample_dict.items():\n",
    "            for frame, files in frames.items():\n",
    "                if all(key in files for key in ['depth', 'Img', 'class', 'instance']):\n",
    "                    self.samples.append(files)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        # 加载 RGB 图像，并转换为 RGB 格式\n",
    "        image = Image.open(sample['Img']).convert('RGB')\n",
    "        # 加载深度图（深度图可能为单通道图像）\n",
    "        depth = Image.open(sample['depth'])\n",
    "        # 加载语义分割标签，通常为单通道标签图\n",
    "        seg = Image.open(sample['class'])\n",
    "        # 加载实例分割标签\n",
    "        inst = Image.open(sample['instance'])\n",
    "        \n",
    "        # 对图像应用预处理 transform\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "        \n",
    "        \n",
    "        depth = GT_transforms(depth)\n",
    "        \n",
    "        seg = GT_transforms(seg)\n",
    "            \n",
    "        inst = GT_transforms(inst)\n",
    "        \n",
    "        return image, depth, seg, inst\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d532c17-7c45-4fc9-896a-4c99b0507b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_color_map(num_colors):\n",
    "    \"\"\"\n",
    "    生成一个包含 num_colors 个随机颜色的映射表。\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # 固定种子，保证每次生成相同的颜色\n",
    "    return np.random.randint(0, 256, (num_colors, 3), dtype=np.uint8)\n",
    "\n",
    "def colorize_panoptic(panoptic_map, colormap):\n",
    "    \"\"\"\n",
    "    根据 panoptic_map 中每个像素的 panoptic_id，从 colormap 中取对应颜色，\n",
    "    生成彩色图像。\n",
    "    \"\"\"\n",
    "    b,c,h, w = panoptic_map.shape\n",
    "    color_image = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    unique_ids = np.unique(panoptic_map[0,0,:,:])\n",
    "    for uid in unique_ids:\n",
    "        # 如果 uid 为 0 或 2550000，设定为黑色\n",
    "        if uid == 2550000:\n",
    "            color = np.array([0, 0, 0], dtype=np.uint8)\n",
    "        else:\n",
    "            # 使用 modulo 确保 uid 超过颜色数量时仍然可以映射\n",
    "            color = colormap[uid % len(colormap)]\n",
    "        color_image[panoptic_map[0,0,:,:] == uid] = color\n",
    "    return color_image\n",
    "# 定义颜色映射表，假设最多256种不同颜色\n",
    "num_colors = 256\n",
    "colormap = get_color_map(num_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346c1d3d-3f7f-48e9-b746-faf0ce222c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt_cls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     28\u001b[0m max_pool \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMaxPool2d(kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, depths, segments, instances \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# print(\"RGB 图像 batch 尺寸:\", images.shape)       # 例如 [4, 3, 256, 512]\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# print(\"深度图 batch 尺寸:\", depths.shape)          # 例如 [4, 1, 256, 512]\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# print(\"语义标签 batch 尺寸:\", segments)       # 例如 [4, 256, 512]\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# print(\"实例标签 batch 尺寸:\", instances.shape)      # 例如 [4, 256, 512]\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# 生成彩色图像\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     gt_pop\u001b[38;5;241m=\u001b[39mgt_cls\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10000\u001b[39m\u001b[38;5;241m+\u001b[39mgt_ins\n\u001b[1;32m     36\u001b[0m     color_image \u001b[38;5;241m=\u001b[39m colorize_panoptic(pop, colormap)\n\u001b[1;32m     37\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(color_image, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gt_cls' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset_root = '/root/autodl-tmp/video_sequence'  # 修改为你的数据集根目录\n",
    "\n",
    "    # 定义图像预处理\n",
    "    image_transforms = transforms.Compose([\n",
    "        transforms.Resize((376, 1241)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    GT_transforms = transforms.Compose([\n",
    "        transforms.Resize((376, 1241),interpolation=transforms.InterpolationMode.NEAREST),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    # 可根据需要为深度图单独定义 transform，例如仅做 resize 和 ToTensor\n",
    "    # 对于 segment 和 instance，由于它们是标签，通常不希望有归一化操作，可以直接转换为 Tensor\n",
    "    # 这里我们在 __getitem__ 中已处理\n",
    "\n",
    "    # 构造训练集\n",
    "    train_dataset = SemKITTI_DVPS_Dataset(root=dataset_root,\n",
    "                                          split='train',\n",
    "                                          image_transform=image_transforms,\n",
    "                                             GT_transform=GT_transforms)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    # 测试加载数据\n",
    "    i=0\n",
    "    max_pool = nn.MaxPool2d(kernel_size=2, stride=1,padding=1)\n",
    "    for images, depths, segments, instances in train_loader:\n",
    "        # print(\"RGB 图像 batch 尺寸:\", images.shape)       # 例如 [4, 3, 256, 512]\n",
    "        # print(\"深度图 batch 尺寸:\", depths.shape)          # 例如 [4, 1, 256, 512]\n",
    "        # print(\"语义标签 batch 尺寸:\", segments)       # 例如 [4, 256, 512]\n",
    "        # print(\"实例标签 batch 尺寸:\", instances.shape)      # 例如 [4, 256, 512]\n",
    "        # 生成彩色图像\n",
    "        gt_pop=segments*10000+instances\n",
    "        color_image = colorize_panoptic(pop, colormap)\n",
    "        img_tensor = torch.tensor(color_image, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "        # 3. 定义最大池化层，kernel_size=2, stride=2（对每个通道独立操作）\n",
    "        \n",
    "\n",
    "        pooled_tensor = max_pool(max_pool(max_pool(img_tensor)))\n",
    "        \n",
    "        # 4. 转换回 NumPy 数组，并将通道维度移到最后，得到形状 (88, 620, 3)\n",
    "        pooled_image = pooled_tensor.squeeze(0).permute(1, 2, 0).numpy().astype(np.uint8)\n",
    "        \n",
    "        img = Image.fromarray(pooled_image)\n",
    "\n",
    "        # 保存图片为 \"output.png\"\n",
    "        img.save(\"/root/autodl-tmp/pop_gt/\"+str(i)+\"_output.png\")\n",
    "        #flag=i%10\n",
    "        i=i+1\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6906a79-e3a0-40ec-8f0b-2b3461d516f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDMSeg",
   "language": "python",
   "name": "ldmseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

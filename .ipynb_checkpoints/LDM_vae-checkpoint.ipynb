{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57f71ec-e269-4510-a91d-c2e4a03ae74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf,open_dict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from dataset.semKITTI_dataset import SemKITTI_DVPS_Dataset\n",
    "from diffusers import AutoencoderKL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from ldmseg.models import GeneralVAESeg\n",
    "from ldmseg.trainers import TrainerAE\n",
    "from ldmseg.utils import prepare_config, Logger, is_main_process\n",
    "import yaml\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0c46be-cc65-4d02-a4fc-8b200269ea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting distributed training yellow\n",
      "Initialized distributed training yellow\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting distributed training\", \"yellow\")\n",
    "dist.init_process_group(backend=\"nccl\",\n",
    "                                init_method=\"tcp://127.0.0.1:54286\",\n",
    "                                world_size=1,\n",
    "                                rank=0)\n",
    "\n",
    "print(\"Initialized distributed training\", \"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51392a39-1997-47c7-a874-02cf7611ad21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation factor:  2\n",
      "Parametrization:  gaussian\n",
      "Activation function:  none\n",
      "GeneralVAESeg(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(11, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): SiLU()\n",
      "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): SiLU()\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (10): SiLU()\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): Identity()\n",
      "    (13): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "    (14): SiLU()\n",
      "    (15): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Conv2d(4, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (3): LayerNorm2d()\n",
      "    (4): SiLU()\n",
      "    (5): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (6): LayerNorm2d()\n",
      "    (7): SiLU()\n",
      "    (8): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    (9): SiLU()\n",
      "    (10): Conv2d(256, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vae_encoder = None\n",
    "# -----------------------\n",
    "# 实例化模型\n",
    "# 对于分类任务，将 out_channels 设置为类别数 19\n",
    "vae = GeneralVAESeg(\n",
    "    in_channels= 11,  # consider bit encoding\n",
    "   int_channels= 256,\n",
    "   out_channels= 11,\n",
    "   block_out_channels= [32, 64, 128, 256],\n",
    "   latent_channels= 4,\n",
    "   num_latents= 2,\n",
    "   num_upscalers= 2,\n",
    "   upscale_channels= 256,\n",
    "   norm_num_groups= 32,\n",
    "   scaling_factor= 0.2,\n",
    "   parametrization= 'gaussian',\n",
    "   act_fn= 'none',\n",
    "   clamp_output= False,\n",
    "   freeze_codebook= False,\n",
    "   num_mid_blocks= 0,\n",
    "   fuse_rgb= False,\n",
    "   resize_input= False,\n",
    "   skip_encoder= False,\n",
    "    encoder=vae_encoder\n",
    ")\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb90f52d-d39d-48c3-95a3-0ccad0bab022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = \"/root/autodl-tmp/latent-diffusion-segmentation/tools/configs/base/base.yaml\"\n",
    "with open(config, 'r', encoding='utf-8') as fin:\n",
    "    p = yaml.load(fin, Loader=yaml.FullLoader)\n",
    "    fin.close()\n",
    "p['name'] = 'segmentation_diffusion'\n",
    "p['train_kwargs']['train_num_steps'] = 100\n",
    "p['lr_scheduler_kwargs'][\"warmup_iters\"]=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc0f549-2a0f-4e0e-b5ec-af1f83a1b77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_dis = \"/root/autodl-tmp/latent-diffusion-segmentation/tools/configs/distributed/local.yaml\"\n",
    "with open(config_dis, 'r', encoding='utf-8') as inf:\n",
    "    cfg_dist = yaml.load(inf, Loader=yaml.FullLoader)\n",
    "    inf.close()\n",
    "cfd={\"distributed\":cfg_dist,\"gpu\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467676f3-e763-402a-82d8-5c9913648e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae = vae.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01993199-409f-4d2d-b14d-4f46566c2998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning -- Using gradient clipping of 3.0\u001b[0m\n",
      "\u001b[31mMost likely not enough memory for training\u001b[0m\n",
      "\u001b[31mPlease use zero redundancy optimizer with adamw\u001b[0m\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: [0.9, 0.999]\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "Train transforms Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    CropResize(size=(512, 512), crop_mode=None)\n",
      "    ToTensor\n",
      "    Identity()\n",
      ")\n",
      "Val transforms Compose(\n",
      "    CropResize(size=(512, 512), crop_mode=None)\n",
      "    ToTensor\n",
      "    Identity()\n",
      ")\n",
      "Found 801 samples in split train\n",
      "<bound method SemKITTI_DVPS_Dataset.__getitem__ of <dataset.semKITTI_dataset.SemKITTI_DVPS_Dataset object at 0x7f9ceb6b61d0>>\n",
      "\u001b[34mThe dataset contains 801 samples\u001b[0m\n",
      "\u001b[33mtraining for 3 epochs or 100 iters per epoch or 300 iterations\u001b[0m\n",
      "\u001b[33mUsing lr scheduler warmup with effective lr: 1.000e-04, final lr: 1.000e-06, warmup iters 50\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " trainer = TrainerAE(\n",
    "         p,\n",
    "        vae,\n",
    "     args=cfd, \n",
    "     results_folder=p['output_dir'],                        # output directory\n",
    "        save_and_sample_every=p['eval_kwargs']['vis_every'],        # save and sample every n iters\n",
    "        cudnn_on=p['train_kwargs']['cudnn'],                        # turn on cudnn\n",
    "        fp16=p['train_kwargs']['fp16'],                             # turn on floating point 16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855ab63e-d4cf-4906-ad43-3c1e7c519b29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mNo saved model at /root/autodl-tmp/model.pt to resume ...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d89c8d-efef-4996-a74f-5590a68f1503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KITTI Eval: 100%|██████████| 101/101 [02:33<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KITTI Evaluation Results:\n",
      "Mean PQ: 0.00%, Mean SQ: 0.00%, Mean RQ: 0.00%\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34mStarting epoch 0\u001b[0m\n",
      "Learning rate is set to: 0.000e+00\n",
      "Epoch: [0][ 99/100]\tLoss 1.1243e+00 (nan)\tCE 5.0618e-02 (nan)\tKL 2.0941e+05 (1.1969e+05)\tMask 1.0737e+00 (1.5516e+00)\n",
      "\u001b[33mModel saved for run segmentation_diffusion\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KITTI Eval: 100%|██████████| 101/101 [02:30<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KITTI Evaluation Results:\n",
      "Mean PQ: 0.00%, Mean SQ: 0.00%, Mean RQ: 0.00%\n",
      "\u001b[33mAverage loss: nan\u001b[0m\n",
      "\u001b[33mEpoch took 0:05:05.843230\u001b[0m\n",
      "\u001b[33mETA: 0:15:26.928123\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34mStarting epoch 1\u001b[0m\n",
      "Learning rate is set to: 1.000e-04\n",
      "Epoch: [1][ 99/100]\tLoss 1.0793e+00 (nan)\tCE 7.2922e-02 (nan)\tKL 2.2446e+05 (2.1894e+05)\tMask 1.0063e+00 (1.0269e+00)\n",
      "\u001b[33mModel saved for run segmentation_diffusion\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KITTI Eval: 100%|██████████| 101/101 [02:31<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KITTI Evaluation Results:\n",
      "Mean PQ: 0.00%, Mean SQ: 0.00%, Mean RQ: 0.00%\n",
      "\u001b[33mAverage loss: nan\u001b[0m\n",
      "\u001b[33mEpoch took 0:05:04.737811\u001b[0m\n",
      "\u001b[33mETA: 0:06:24.101020\u001b[0m\n",
      "\u001b[34m-------------------------\u001b[0m\n",
      "\u001b[34mStarting epoch 2\u001b[0m\n",
      "Learning rate is set to: 1.000e-04\n",
      "Epoch: [2][ 99/100]\tLoss 1.0066e+00 (nan)\tCE 8.6001e-03 (nan)\tKL 2.2321e+05 (2.2420e+05)\tMask 9.9804e-01 (9.8225e-01)\n",
      "\u001b[33mModel saved for run segmentation_diffusion\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KITTI Eval: 100%|██████████| 101/101 [02:30<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KITTI Evaluation Results:\n",
      "Mean PQ: 0.00%, Mean SQ: 0.00%, Mean RQ: 0.00%\n",
      "\u001b[33mAverage loss: nan\u001b[0m\n",
      "\u001b[33mEpoch took 0:05:05.362331\u001b[0m\n",
      "\u001b[33mETA: 0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KITTI Eval: 100%|██████████| 101/101 [02:31<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KITTI Evaluation Results:\n",
      "Mean PQ: 0.00%, Mean SQ: 0.00%, Mean RQ: 0.00%\n",
      "Finished run segmentation_diffusion and took 0:20:27.551457\n"
     ]
    }
   ],
   "source": [
    "if p['load_path'] is not None:\n",
    "    trainer.load(model_path=p['load_path'])  # looks for model at load_path\n",
    "\n",
    "if p['eval_only']:\n",
    "    trainer.compute_metrics(['miou', 'pq'])\n",
    "    \n",
    "\n",
    "    # train\n",
    "trainer.train_loop()\n",
    "\n",
    "# terminate wandb\n",
    "if p['wandb'] and is_main_process():\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d41b4-2b25-4932-bb7d-a71c00f11729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDMSeg",
   "language": "python",
   "name": "ldmseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
